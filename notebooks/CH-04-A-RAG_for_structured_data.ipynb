{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18002aa6-39a1-4e71-8749-324e2f615f31",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Reto 04-A - Generación Aumentada con Recuperación (RAG) para Datos Estructurados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4ca1751",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este notebook, exploraremos la aplicación práctica de RAG con un tipo de datos más manejable, es decir, datos estructurados como datos relacionales o datos de texto almacenados en archivos CSV. El objetivo principal es introducir un caso de uso específico que demuestre la utilización de Azure AI Search para extraer documentos relevantes y el poder de ChatGPT para abordar las partes relevantes del documento, proporcionando resúmenes concisos basados en los prompts del usuario. Tiene como objetivo mostrar cómo se pueden adaptar las capacidades de ChatGPT de Azure OpenAI a tus necesidades de resumen, al mismo tiempo que te guía a través de la configuración y evaluación de los resultados del resumen. Este método se puede personalizar para adaptarse a varios casos de uso de resumen y aplicarse a diversos conjuntos de datos.\n",
    "\n",
    "Tus objetivos para este desafío son leer este notebook, ejecutar cada bloque de código, observar los resultados y luego poder responder las preguntas planteadas en la guía del estudiante."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f2d0025-3952-481b-9615-cfe5ee198f66",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Caso de Uso\n",
    "\n",
    "Este caso de uso consta de tres secciones:\n",
    "- Búsqueda de Documentos: El proceso de extraer documentos relevantes en función de la consulta de un corpus de documentos.\n",
    "- Búsqueda de Zona de Documentos: El proceso de encontrar la parte relevante del documento extraído de la búsqueda de documentos.\n",
    "- Tareas de IA posteriores, como Responder a Preguntas (también conocidas como Resumen de Texto): el resumen de texto es el proceso de crear resúmenes a partir de grandes volúmenes de datos manteniendo elementos informativos significativos y valor de contenido.\n",
    "\n",
    "Este caso de uso puede ser útil para ayudar a expertos en la materia a encontrar información relevante en un gran corpus de documentos.\n",
    "\n",
    "**Ejemplo:** En el proceso de descubrimiento de medicamentos, los científicos de la industria farmacéutica leen un corpus de documentos para encontrar información específica relacionada con conceptos, resultados de experimentos, etc. Este caso de uso les permite hacer preguntas al corpus de documentos y la solución devolverá la respuesta sucinta. En consecuencia, se acelera el proceso de descubrimiento de medicamentos.\n",
    " \n",
    "Beneficios de la solución:\n",
    "1. Acorta el tiempo de lectura.\n",
    "2. Mejora la efectividad de la búsqueda de información.\n",
    "3. Elimina el sesgo de las técnicas de resumen humanas.\n",
    "4. Aumenta la capacidad para que los humanos se enfoquen en análisis más profundos.\n",
    "\n",
    "La necesidad de resumen de documentos puede aplicarse a cualquier tema (legal, financiero, periodístico, médico, académico, etc.) que requiera un resumen de documentos largos. El tema en el que se centra este notebook es periodístico: recorreremos artículos de noticias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85743c37-40f6-493f-9eaa-e9c4857ba8eb",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Conjunto de Datos de CNN y Daily Mail\n",
    "Para este tutorial, utilizaremos el conjunto de datos de CNN/Daily Mail. Se trata de un conjunto de datos comúnmente utilizado para tareas de resumen de texto y respuesta a preguntas. Se generaron resúmenes abstractivos humanos a partir de historias de noticias en los sitios web de CNN y Daily Mail.\n",
    "\n",
    "### Descripción de los Datos\n",
    "El esquema relevante para nuestro trabajo de hoy consiste en:\n",
    "\n",
    "- `id`: una cadena que contiene el hash SHA1 con formato hexadecimal de la URL de donde se recuperó la noticia.\n",
    "- `article`: una cadena de caracteres que contiene el cuerpo del artículo de noticias.\n",
    "- `highlights`: una cadena de caracteres que contiene lo más destacado del artículo tal como lo escribió el autor del artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bd738e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Azure Cognitive Search, OpenAI, and other python modules\n",
    "\n",
    "import os, json, requests, sys, re\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient \n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSettings\n",
    ")\n",
    "\n",
    "\n",
    "import openai\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4cc4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is secure and recommended way to load OpenAI resource credentials and deployment names\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "openai.api_version = os.environ['OPENAI_API_VERSION']\n",
    "\n",
    "chat_model = os.environ['CHAT_MODEL_NAME']\n",
    "embedding_model=os.environ['EMBEDDING_MODEL_NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c44e3",
   "metadata": {},
   "source": [
    "**NOTA:** La ruta en la celda de código a continuación hace referencia al archivo `cnn_dailymail.csv` en la carpeta `/data/structured/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9019bf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
       "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
       "      <td>Experts question if  packed out planes are put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
       "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
       "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
       "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
       "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
       "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
       "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
       "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
       "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
       "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
       "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
       "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
       "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
       "\n",
       "                                             article  \\\n",
       "0  Ever noticed how plane seats appear to be gett...   \n",
       "1  A drunk teenage boy had to be rescued by secur...   \n",
       "2  Dougie Freedman is on the verge of agreeing a ...   \n",
       "3  Liverpool target Neto is also wanted by PSG an...   \n",
       "4  Bruce Jenner will break his silence in a two-h...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Experts question if  packed out planes are put...  \n",
       "1  Drunk teenage boy climbed into lion enclosure ...  \n",
       "2  Nottingham Forest are close to extending Dougi...  \n",
       "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
       "4  Tell-all interview with the reality TV star, 6...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the CNN dailymail dataset in pandas dataframe\n",
    "df = pd.read_csv('../data/structured/cnn_dailymail_data.csv') #path to CNN daily mail dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11eff67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.search.documents.indexes._search_index_client.SearchIndexClient at 0x787546d53080>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Cognitive Search Index client\n",
    "service_endpoint = os.getenv(\"AZURE_COGNITIVE_SEARCH_ENDPOINT\")   \n",
    "key = os.getenv(\"AZURE_COGNITIVE_SEARCH_KEY\")\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "index_name = os.getenv(\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\")\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "index_client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b30a67db",
   "metadata": {},
   "source": [
    "### Definir Campos del Índice y Crear una Configuración Semántica\n",
    "\n",
    "Una *configuración semántica* especifica cómo se utilizan los campos en la clasificación semántica. Da a los modelos subyacentes pistas sobre qué campos de índice son más importantes para la clasificación semántica, los subtítulos, los destacados y las respuestas.\n",
    "\n",
    "Puedes agregar o actualizar una configuración semántica en cualquier momento sin reconstruir tu índice. Cuando emites una consulta, añadirás la configuración semántica (una por consulta) que especifica qué configuración semántica usar para la consulta.\n",
    "\n",
    "Revisa las propiedades que necesitarás especificar. Una configuración semántica tiene un nombre y al menos una de cada una de las siguientes propiedades:\n",
    "\n",
    "* Campo de título: Un campo de título debe ser una descripción concisa del documento, idealmente una cadena de menos de 25 palabras. Este campo podría ser el título del documento, el nombre del producto o el elemento en tu índice de búsqueda. Si no tienes un título en tu índice de búsqueda, deja este campo en blanco.\n",
    "* Campos de contenido: Los campos de contenido deben contener texto en formato de lenguaje natural. Ejemplos comunes de contenido son el cuerpo de un documento, la descripción de un producto u otro texto en forma libre.\n",
    "* Campos de palabras clave: Los campos de palabras clave deben ser una lista de palabras clave, como las etiquetas en un documento, o un término descriptivo, como la categoría de un artículo.\n",
    "\n",
    "Solo puedes especificar un campo de título, pero puedes especificar tantos campos de contenido y palabras clave como desees. Para los campos de contenido y palabras clave, enumera los campos en orden de prioridad porque los campos de menor prioridad pueden ser truncados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a325dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " news-index-labp2 created\n"
     ]
    }
   ],
   "source": [
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"highlights\", type=SearchFieldDataType.String,\n",
    "                searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"article\", type=SearchFieldDataType.String,\n",
    "                filterable=True, searchable=True, retrievable=True),\n",
    "]\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        #title_field=SemanticField(field_name=\"\"), # title field is not present in the dataset. We can use OpenAI to generate title\n",
    "        #prioritized_keywords_fields=[SemanticField(field_name=\"\")], # keywords are not present in the dataset. We can use OpenAI to generate keywords\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"article\"), SemanticField(field_name=\"highlights\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a028ea64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '92c514c913c0bdfe25341af9fd72b29db544099b',\n",
       " 'article': \"Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.\\xa0'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\",\n",
       " 'highlights': 'Experts question if  packed out planes are putting passengers at risk .\\nU.S consumer advisory group says minimum space must be stipulated .\\nSafety tests conducted on planes with more leg room than airlines offer .'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dataframe to a list of dictionaries\n",
    "documents = df.to_dict('records')\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b3fe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11490"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9022d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded and Indexed 11490 documents\n"
     ]
    }
   ],
   "source": [
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)  \n",
    "print(f\"Uploaded and Indexed {len(result)} documents\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc09a779-e3cd-485f-ae3a-297491d993b0",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sección 1: Aprovechar la Búsqueda Cognitiva para extraer artículos relevantes basados en la consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32689db7-4337-42d9-b8f9-4cbd9d98a850",
   "metadata": {
    "gather": {
     "logged": 1675138710195
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Extracting relevant article based on the query. eg: Clinton Democratic Nomination\n",
    "results = search_client.search(search_text=\"Clinton Democratic nomination\", include_total_count=True)\n",
    "document = next(results)['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c9681f2-2448-4e6d-8174-5fb5ff61d5db",
   "metadata": {
    "gather": {
     "logged": 1675139624461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(CNN)Hillary Clinton is now officially a candidate for president -- and the never ending Clinton story rumbles on. She has been a part of all our lives now for approaching a quarter of a century. She started as the first lady that the right loved to hate, then the deceived wife, next a senator, then a candidate for president in one of the most dynamic primaries in history and finally, a secretary of state. The Republicans have their aristocratic Bushes, the Democrats have their Clintons. And if Hillary or Jeb were to win two presidential terms, then in the 44 years from 1981 to 2025, 28 will have had a Clinton or a Bush in the White House. The great American republic now looks about as democratic as \"Game of Thrones.\" But even though Hillary Clinton has been around nearly my entire lifetime, The Economist may speak for many when it asks: \"What does Hillary stand for?\" There is a paradox she presents: She is by far the best-known presidential candidate across both parties and, for the moment, almost unchallenged within her own. Yet even though Diane Feinstein can assert confidently that Hillary \"doesn\\'t \\'need\\' (the White House). But she wants it\" -- the question unanswered is \"What for?\" And for liberals, who believe that government is there to do something, it\\'s this lack of definition that is surely so disconcerting about Clinton. There are good grounds for a liberal primary challenge to Clinton. The economy has revived under Obama but, say critics, largely to the benefit of Wall Street and the super-rich. The riots in Ferguson, Missouri, were a painful reminder that the poor, particularly the nonwhite poor, have been left behind. Clinton\\'s credentials as a fighter against inequality are mixed. It is true, as the Wall Street Times notes, that she has previously called for \"universal prekindergarten, equal pay for women, increases in the minimum wage, paid family leave, higher taxes on the wealthy and an expanded Earned Income Tax Credit for working-poor families.\" But she counts among her friends precisely those corporate people blamed by the Occupy crowd for the country\\'s inequality. Clinton is now, wisely, trying to distance herself from the Clinton Foundation -- after all, its fundraising efforts among foreign interests are hardly the stuff of populist liberalism. Then there is her foreign policy record. Clinton voted in 2002 to authorize the Iraq War (though in her memoir last year, she backed away from the vote, writing that she \"got it wrong.\") As secretary of state, she is easily associated in the mind of the left with such controversies as the war in Syria, the crisis in Libya and the collapse of the Mubarak regime in Egypt. That some of these may have had little to do with her is beside the point. Clinton is going to have to spend a sizeable amount of time during the primaries explaining and defending the things that occurred while she was working for the Obama administration. Her personal ethics are on the agenda, too -- as demonstrated by the flap over her use of a private email account. These are the issues that her Democratic rivals are running on. In Iowa last week, both Jim Webb and Martin O\\'Malley attacked Wall Street, Webb adding that he had also opposed the Iraq War. Both men questioned the wisdom of Clintonian triangulation -- the idea that the White House can be won, and the country successfully governed, by always seeking the middle ground. Both men would be wise to focus on Iowa; to contrast a populist, folksy campaign with the distant, over-managed style of Clinton. And both would do well to tap into a feeling that it would be unhealthy, undemocratic and plain dull to let Hillary coast to the nomination without a proper challenge. Nevertheless, there is a strange contradiction between the constant assertions that Democrats want a race and the polling evidence that Clinton would beat anyone who tried to take her on. Why do liberals demand a conversation about policy if the only answer they can still come up with is Hillary? The explanation is that the Democratic Party is intellectually impoverished. We hear often of the GOP\\'s problems, how out of touch with a changing electorate it is and how it is divided against itself. The Democrats\\' challenges, however, are just as substantial. They\\'ve just been masked by having a charismatic man in the White House dominating the national conversation. Obama was elected at one of the highest points of national Democratic popularity. But, since then, Democratic power has been whittled away in successive congressional and local elections -- leaving the party without significant representation in the Deep South and absent any mildly conservative support at all. Everything was staked on Obamacare, which was ambitious and noble venture but without an obvious second act to follow. Democrats have become about defending the honor and reputation of their president rather than proposing bold new reforms. And the mood of their base can be felt either in the violence in Missouri or the disaffected, hollow laughter of \"The Daily Show\" audience. Cynicism abounds. Who really imagines that Hillary Clinton is the kind of personality that can spark a renaissance of thinking or a rejuvenation of activism among liberals? To repeat the question: what is she exactly running for? If she has one trump card to play, however, it is reinvention. Recall that she started the 2008 primaries out as a moderate, play-it-safe frontrunner and ended them drinking beer in an Indiana bar -- reinvented, in the words of Barack Obama, as Annie Oakley. If there is little intellectualism left in liberalism, at least Hillary Clinton is clever. Which is why she remains an asset to her party.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02375dcd-514e-4203-951e-729b3de07570",
   "metadata": {
    "gather": {
     "logged": 1675139635796
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of article extracted from Azure Cognitive search\n",
    "len(document) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30b4b060-1dca-468c-a1f5-ac1b9e5d4878",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sección 2: Búsqueda de Zona de Documentos\n",
    "### Zona de Documentos: API de Embeddings de Azure OpenAI\n",
    "Ahora que nos hemos enfocado en un solo documento de nuestra base de conocimientos usando Azure AI Search, podemos profundizar en dicho documento único para refinar nuestra consulta inicial a una sección más específica o \"zona\" del artículo.\n",
    "\n",
    "Para hacer esto, utilizaremos la API de Embeddings de Azure OpenAI.\n",
    "\n",
    "### **Descripción general de los Embeddings**\n",
    "Un embedding es un formato especial de representación de datos que puede ser fácilmente utilizado por modelos y algoritmos de machine learning. El embedding es una representación densa en información del significado semántico de un fragmento de texto. Cada embedding es un vector de números de punto flotante, de modo que la distancia entre dos embeddings en el espacio vectorial está correlacionada con la similitud semántica entre dos entradas en el formato original. Por ejemplo, si dos textos son similares, entonces sus representaciones vectoriales también deberían ser similares.\n",
    "\n",
    "Diferentes modelos de embedding de Azure OpenAI están específicamente creados para ser buenos en una tarea particular. Los embeddings de similitud son buenos para capturar la similitud semántica entre dos o más fragmentos de texto. Los embeddings de búsqueda de texto ayudan a medir qué documentos largos son relevantes para una consulta corta. Los embeddings de búsqueda de código son útiles para vectorizar fragmentos de código y consultas de búsqueda en lenguaje natural.\n",
    "\n",
    "Los embeddings facilitan el machine learning en grandes entradas que representan palabras al capturar las similitudes semánticas en un espacio vectorial. Por lo tanto, podemos usar embeddings para determinar si dos fragmentos de texto están semánticamente relacionados o son similares, y de manera inherente proporcionar una puntuación para evaluar la similitud.\n",
    "\n",
    "### **Similitud de Coseno**\n",
    "Un enfoque utilizado anteriormente para localizar documentos similares se basaba en contar el número máximo de palabras comunes entre documentos. Esto es defectuoso ya que, a medida que aumenta el tamaño del documento, aumenta la superposición de palabras comunes incluso si los temas difieren. Por lo tanto, la similitud del coseno es un mejor enfoque.\n",
    "\n",
    "Matemáticamente, la similitud del coseno mide el coseno del ángulo entre dos vectores proyectados en un espacio multidimensional. Esto es beneficioso porque si dos documentos están muy separados por la distancia euclidiana debido al tamaño, aún podrían tener un ángulo más pequeño entre ellos y, por lo tanto, una mayor similitud del coseno.\n",
    "\n",
    "Los embeddings de Azure OpenAI se basan en la similitud del coseno para calcular la similitud entre documentos y una consulta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cf78f21-368a-4314-ab59-f5be527e4b08",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Configuración del servicio de Azure OpenAI y uso de modelos implementados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c178e3be",
   "metadata": {},
   "source": [
    "### **Chunking**\n",
    "\n",
    "Comencemos con la segmentación (chunking). ¿Por qué es importante chunking al trabajar con LLMs?\n",
    "\n",
    "Chunking ayuda a superar los desafíos asociados con el procesamiento de secuencias largas y garantiza un rendimiento óptimo al trabajar con LLMs.\n",
    "\n",
    "**Mitigación de Limitaciones de Tokens:** Los LLMs tienen un límite máximo de tokens para cada secuencia de entrada. Si un documento o entrada excede este límite, necesita dividirse en fragmentos que se ajusten a las restricciones de tokens. Chunking permite que el LLM maneje documentos largos o entradas dividiéndolos en múltiples fragmentos que caen dentro del límite de tokens. Esto asegura que el modelo pueda procesar efectivamente todo el contenido mientras se adhiere a las restricciones de tokens.\n",
    "\n",
    "**Eficiencia de Memoria y Computacional:** Los LLMs son computacionalmente costosos y requieren recursos de memoria sustanciales para procesar secuencias largas de texto. Chunking implica descomponer documentos largos o entradas en fragmentos más pequeños y manejables, permitiendo que el LLM los procese eficientemente dentro de sus limitaciones de memoria. Al dividir la entrada en partes más pequeñas, chunking ayuda a evitar errores de memoria o degradación del rendimiento que pueden ocurrir al procesar secuencias largas.\n",
    "\n",
    "**Coherencia Contextual:** Chunking ayuda a mantener la coherencia contextual en las salidas generadas. En lugar de tratar toda la entrada como una sola secuencia, dividirla en fragmentos más pequeños permite que el modelo capture el contexto local de manera más efectiva. Esto mejora la comprensión del modelo de las relaciones y dependencias dentro del texto, lo que lleva a respuestas generadas más coherentes y significativas.\n",
    "\n",
    "**Paralelismo Mejorado:** Chunking permite el procesamiento paralelo, lo cual es esencial para optimizar el rendimiento de los LLMs. Al dividir la entrada en fragmentos, se pueden procesar múltiples fragmentos simultáneamente, aprovechando las capacidades de computación paralela. Esto conduce a tiempos de inferencia más rápidos y mejora la eficiencia general al trabajar con LLMs.\n",
    "\n",
    "Utilizaremos un splitter básico para este notebook. Sin embargo, es importante tener en cuenta que existen splitters más avanzados disponibles, que pueden adaptarse mejor a tu caso de uso específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b043fbb4",
   "metadata": {
    "gather": {
     "logged": 1675138711079
    }
   },
   "outputs": [],
   "source": [
    "#Defining helper functions\n",
    "#Splits text after sentences ending in a period. Combines n sentences per chunk.\n",
    "def splitter(n, s):\n",
    "    pieces = s.split(\". \")\n",
    "    list_out = [\" \".join(pieces[i:i+n]) for i in range(0, len(pieces), n)]\n",
    "    return list_out\n",
    "\n",
    "# Perform light data cleaning (removing redudant whitespace and cleaning up punctuation)\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56354758-427f-4af9-94b9-96a25946e9a5",
   "metadata": {
    "gather": {
     "logged": 1675138711316
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(CNN)Hillary Clinton is now officially a candidate for president -- and the never ending Clinton story rumbles on She has been a part of all our lives now for approaching a quarter of a century She started as the first lady that the right loved to hate, then the deceived wife, next a senator, then a candidate for president in one of the most dynamic primaries in history and finally, a secretary of state The Republicans have their aristocratic Bushes, the Democrats have their Clintons And if Hillary or Jeb were to win two presidential terms, then in the 44 years from 1981 to 2025, 28 will have had a Clinton or a Bush in the White House The great American republic now looks about as democratic as \"Game of Thrones.\" But even though Hillary Clinton has been around nearly my entire lifetime, The Economist may speak for many when it asks: \"What does Hillary stand for?\" There is a paradox she presents: She is by far the best-known presidential candidate across both parties and, for the moment, almost unchallenged within her own Yet even though Diane Feinstein can assert confidently that Hillary \"doesn\\'t \\'need\\' (the White House) But she wants it\" -- the question unanswered is \"What for?\" And for liberals, who believe that government is there to do something, it\\'s this lack of definition that is surely so disconcerting about Clinton There are good grounds for a liberal primary challenge to Clinton The economy has revived under Obama but, say critics, largely to the benefit of Wall Street and the super-rich',\n",
       " 'The riots in Ferguson, Missouri, were a painful reminder that the poor, particularly the nonwhite poor, have been left behind Clinton\\'s credentials as a fighter against inequality are mixed It is true, as the Wall Street Times notes, that she has previously called for \"universal prekindergarten, equal pay for women, increases in the minimum wage, paid family leave, higher taxes on the wealthy and an expanded Earned Income Tax Credit for working-poor families.\" But she counts among her friends precisely those corporate people blamed by the Occupy crowd for the country\\'s inequality Clinton is now, wisely, trying to distance herself from the Clinton Foundation -- after all, its fundraising efforts among foreign interests are hardly the stuff of populist liberalism Then there is her foreign policy record Clinton voted in 2002 to authorize the Iraq War (though in her memoir last year, she backed away from the vote, writing that she \"got it wrong.\") As secretary of state, she is easily associated in the mind of the left with such controversies as the war in Syria, the crisis in Libya and the collapse of the Mubarak regime in Egypt That some of these may have had little to do with her is beside the point Clinton is going to have to spend a sizeable amount of time during the primaries explaining and defending the things that occurred while she was working for the Obama administration Her personal ethics are on the agenda, too -- as demonstrated by the flap over her use of a private email account These are the issues that her Democratic rivals are running on',\n",
       " \"In Iowa last week, both Jim Webb and Martin O'Malley attacked Wall Street, Webb adding that he had also opposed the Iraq War Both men questioned the wisdom of Clintonian triangulation -- the idea that the White House can be won, and the country successfully governed, by always seeking the middle ground Both men would be wise to focus on Iowa; to contrast a populist, folksy campaign with the distant, over-managed style of Clinton And both would do well to tap into a feeling that it would be unhealthy, undemocratic and plain dull to let Hillary coast to the nomination without a proper challenge Nevertheless, there is a strange contradiction between the constant assertions that Democrats want a race and the polling evidence that Clinton would beat anyone who tried to take her on Why do liberals demand a conversation about policy if the only answer they can still come up with is Hillary? The explanation is that the Democratic Party is intellectually impoverished We hear often of the GOP's problems, how out of touch with a changing electorate it is and how it is divided against itself The Democrats' challenges, however, are just as substantial They've just been masked by having a charismatic man in the White House dominating the national conversation Obama was elected at one of the highest points of national Democratic popularity\",\n",
       " 'But, since then, Democratic power has been whittled away in successive congressional and local elections -- leaving the party without significant representation in the Deep South and absent any mildly conservative support at all Everything was staked on Obamacare, which was ambitious and noble venture but without an obvious second act to follow Democrats have become about defending the honor and reputation of their president rather than proposing bold new reforms And the mood of their base can be felt either in the violence in Missouri or the disaffected, hollow laughter of \"The Daily Show\" audience Cynicism abounds Who really imagines that Hillary Clinton is the kind of personality that can spark a renaissance of thinking or a rejuvenation of activism among liberals? To repeat the question: what is she exactly running for? If she has one trump card to play, however, it is reinvention Recall that she started the 2008 primaries out as a moderate, play-it-safe frontrunner and ended them drinking beer in an Indiana bar -- reinvented, in the words of Barack Obama, as Annie Oakley If there is little intellectualism left in liberalism, at least Hillary Clinton is clever Which is why she remains an asset to her party.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chunks = splitter(10, normalize_text(document)) #splitting extracted document into chunks of 10 sentences\n",
    "document_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b3c83f-deca-493b-aa41-12b89f24feff",
   "metadata": {
    "gather": {
     "logged": 1675138711716
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Handling Rate Limits\n",
    "\n",
    "from openai.error import RateLimitError\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def get_embedding(text: str, engine: str = \"text-embedding-ada-002\"):\n",
    "    count=0\n",
    "    while True:\n",
    "        try:\n",
    "            embedding = openai.Embedding().create(input=[text], engine=engine)[\"data\"][0][\"embedding\"]\n",
    "            break;\n",
    "        except RateLimitError:\n",
    "            count+=1\n",
    "            #print(f'RateLimitError Count: {count}')\n",
    "            sleep(2)            \n",
    "    return np.array(embedding).astype(np.float32)\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-35-turbo\", temperature=0): \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de635ba5-7cf1-4d4f-8598-73619fc9c7ef",
   "metadata": {
    "gather": {
     "logged": 1675138711984
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)Hillary Clinton is now officially a candi...</td>\n",
       "      <td>[-0.02244035, -0.010071911, -0.0031363997, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The riots in Ferguson, Missouri, were a painfu...</td>\n",
       "      <td>[-0.005809085, -0.029980645, -0.015955709, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Iowa last week, both Jim Webb and Martin O'...</td>\n",
       "      <td>[-0.014524365, -0.0053608236, 0.026020017, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But, since then, Democratic power has been whi...</td>\n",
       "      <td>[-0.021648454, -0.0040004035, 0.011662534, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chunks  \\\n",
       "0  (CNN)Hillary Clinton is now officially a candi...   \n",
       "1  The riots in Ferguson, Missouri, were a painfu...   \n",
       "2  In Iowa last week, both Jim Webb and Martin O'...   \n",
       "3  But, since then, Democratic power has been whi...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.02244035, -0.010071911, -0.0031363997, -0....  \n",
       "1  [-0.005809085, -0.029980645, -0.015955709, -0....  \n",
       "2  [-0.014524365, -0.0053608236, 0.026020017, -0....  \n",
       "3  [-0.021648454, -0.0040004035, 0.011662534, -0....  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df = pd.DataFrame(document_chunks, columns = [\"chunks\"]) #datframe with document chunks\n",
    "\n",
    "#Create an embedding vector for each chunk that will capture the semantic meaning and overall topic of that chunk\n",
    "embed_df['embeddings'] = embed_df[\"chunks\"].apply(lambda x : get_embedding(x, engine = embedding_model))\n",
    "\n",
    "embed_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cc7adb8-93dd-4dfd-995a-8df893a98d99",
   "metadata": {
    "gather": {
     "logged": 1675138712417
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# search through the document for a text segment most similar to the query\n",
    "# display top two most similar chunks based on cosine similarity\n",
    "def search_docs(df, user_query, top_n=3):\n",
    "    embedding = get_embedding(\n",
    "        user_query,\n",
    "        engine=embedding_model,\n",
    "    )\n",
    "    df[\"similarities\"] = df['embeddings'].apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8511f3a-198f-4e8f-8a5d-cb74456826fa",
   "metadata": {
    "gather": {
     "logged": 1675138712650
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Iowa last week, both Jim Webb and Martin O'...</td>\n",
       "      <td>[-0.014524365, -0.0053608236, 0.026020017, -0....</td>\n",
       "      <td>0.848953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The riots in Ferguson, Missouri, were a painfu...</td>\n",
       "      <td>[-0.005809085, -0.029980645, -0.015955709, -0....</td>\n",
       "      <td>0.843543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chunks  \\\n",
       "0  In Iowa last week, both Jim Webb and Martin O'...   \n",
       "1  The riots in Ferguson, Missouri, were a painfu...   \n",
       "\n",
       "                                          embeddings  similarities  \n",
       "0  [-0.014524365, -0.0053608236, 0.026020017, -0....      0.848953  \n",
       "1  [-0.005809085, -0.029980645, -0.015955709, -0....      0.843543  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_specific_query = \"trouble so far in clinton campaign\" \n",
    "res = search_docs(embed_df, document_specific_query, top_n=2) #finding top 2 results based on similarity \n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eabac33e-5a98-49f0-8fd6-2750bcf79bb1",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sección 3: Resumen de Texto\n",
    "\n",
    "Esta sección trata del flujo de principio a fin del uso de los modelos GPT-3 y ChatGPT para tareas de resumen. El modelo utilizado por el servicio Azure OpenAI es una llamada de completado generativo que utiliza instrucciones en lenguaje natural para identificar la tarea solicitada y la habilidad requerida, también conocido como Prompt Engineering. Usando este enfoque, la primera parte del prompt incluye instrucciones en lenguaje natural y/o ejemplos de la tarea específica deseada. Luego, el modelo completa la tarea prediciendo el próximo texto más probable. Esta técnica se conoce como aprendizaje \"en contexto\".\n",
    "\n",
    "Hay tres enfoques principales para el aprendizaje en contexto: Zero-shot, Few-shot y Fine-tuning. Estos enfoques varían según la cantidad de datos específicos de la tarea que se proporcionan al modelo:\n",
    "\n",
    "**Zero-shot (cero disparos):** En este caso, no se proporcionan ejemplos al modelo y solo se proporciona la solicitud de la tarea.\n",
    "\n",
    "**Few-shot (pocos disparos):** En este caso, un usuario incluye varios ejemplos en el prompt de llamada que demuestran el formato y el contenido de la respuesta esperada.\n",
    "\n",
    "**Fine-Tuning (ajuste preciso):** Fine Tuning te permite adaptar los modelos a tus conjuntos de datos personales. Este paso de personalización te permitirá obtener más del servicio proporcionando:\n",
    "-   Con muchos datos (al menos 500 y más), se utilizan técnicas de optimización tradicionales con Back Propagation para reajustar los pesos del modelo - esto permite obtener resultados de mayor calidad que las técnicas simples de zero-shot o few-shot.\n",
    "-   Un modelo personalizado mejora el enfoque de few-shot learning (aprendizaje de pocos disparos) al entrenar los pesos del modelo en tus prompts y estructuras específicas. Esto te permite lograr mejores resultados en una mayor cantidad de tareas sin necesidad de proporcionar ejemplos en el prompt. El resultado es menos texto enviado y menos tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8e47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the content about the Clinton campaign given the text provided.\n",
      "\n",
      "Text:\n",
      "In Iowa last week, both Jim Webb and Martin O'Malley attacked Wall Street, Webb adding that he had also opposed the Iraq War Both men questioned the wisdom of Clintonian triangulation -- the idea that the White House can be won, and the country successfully governed, by always seeking the middle ground Both men would be wise to focus on Iowa; to contrast a populist, folksy campaign with the distant, over-managed style of Clinton And both would do well to tap into a feeling that it would be unhealthy, undemocratic and plain dull to let Hillary coast to the nomination without a proper challenge Nevertheless, there is a strange contradiction between the constant assertions that Democrats want a race and the polling evidence that Clinton would beat anyone who tried to take her on Why do liberals demand a conversation about policy if the only answer they can still come up with is Hillary? The explanation is that the Democratic Party is intellectually impoverished We hear often of the GOP's problems, how out of touch with a changing electorate it is and how it is divided against itself The Democrats' challenges, however, are just as substantial They've just been masked by having a charismatic man in the White House dominating the national conversation Obama was elected at one of the highest points of national Democratic popularity\n",
      "\n",
      "Text:\n",
      "The riots in Ferguson, Missouri, were a painful reminder that the poor, particularly the nonwhite poor, have been left behind Clinton's credentials as a fighter against inequality are mixed It is true, as the Wall Street Times notes, that she has previously called for \"universal prekindergarten, equal pay for women, increases in the minimum wage, paid family leave, higher taxes on the wealthy and an expanded Earned Income Tax Credit for working-poor families.\" But she counts among her friends precisely those corporate people blamed by the Occupy crowd for the country's inequality Clinton is now, wisely, trying to distance herself from the Clinton Foundation -- after all, its fundraising efforts among foreign interests are hardly the stuff of populist liberalism Then there is her foreign policy record Clinton voted in 2002 to authorize the Iraq War (though in her memoir last year, she backed away from the vote, writing that she \"got it wrong.\") As secretary of state, she is easily associated in the mind of the left with such controversies as the war in Syria, the crisis in Libya and the collapse of the Mubarak regime in Egypt That some of these may have had little to do with her is beside the point Clinton is going to have to spend a sizeable amount of time during the primaries explaining and defending the things that occurred while she was working for the Obama administration Her personal ethics are on the agenda, too -- as demonstrated by the flap over her use of a private email account These are the issues that her Democratic rivals are running on\n",
      "\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Designing a prompt that will show and tell GPT-3 how to proceed. \n",
    "+ Providing an instruction to summarize the text about the general topic (prefix)\n",
    "+ Providing quality data for the chunks to summarize and specifically mentioning they are the text provided (context + context primer)\n",
    "+ Providing a space for GPT-3 to fill in the summary to follow the format (suffix)\n",
    "'''\n",
    "\n",
    "# result_1 corresponding to the top chunk from Section 2. result_2 corresponding to the second to top chunk from section 2. \n",
    "# change index for desired chunk\n",
    "result_1 = res.chunks[0]\n",
    "result_2 = res.chunks[1]\n",
    "prompt_i = 'Summarize the content about the Clinton campaign given the text provided.\\n\\nText:\\n'+\" \".join([normalize_text(result_1)])+ '\\n\\nText:\\n'+ \" \".join([normalize_text(result_2)])+'\\n\\nSummary:\\n'\n",
    "print(prompt_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ec85c16-daec-4eb3-aa33-bed7c20774b6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Clinton campaign is facing criticism from Democratic rivals who are questioning her credentials as a fighter against inequality and her foreign policy record. Her friends in corporate America and the Clinton Foundation's fundraising efforts among foreign interests are also being scrutinized. Her personal ethics, including the use of a private email account, are also on the agenda. Despite calls for a proper challenge, polling evidence suggests that Clinton would beat anyone who tried to take her on, highlighting the intellectual impoverishment of the Democratic Party.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(prompt_i, model=chat_model) # default temperature is set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1449c949-1a01-4f20-bebb-e7674ac6de43",
   "metadata": {
    "gather": {
     "logged": 1675138714150
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Clinton campaign is facing challenges from Democratic rivals who are questioning her credentials as a fighter against inequality and her foreign policy record. Her ties to corporate interests and the Clinton Foundation's fundraising efforts among foreign interests are also being scrutinized. The Democratic Party is intellectually impoverished and needs a proper challenge to avoid letting Clinton coast to the nomination. Despite demands for a conversation about policy, polling evidence suggests that Clinton would beat anyone who tried to take her on.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bumping up the temperature to 0.5 to increase the randomness of the model's output\n",
    "get_completion(prompt_i, model=chat_model, temperature=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
